{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Function to read the input dataset as per the prescribed format in the feature map.\n",
    "def readGermanCreditDataset(fname):\n",
    "    inputData = []\n",
    "# inputData = np.fromfile(\"german.adcg.trainingd\", dtype=dt)#np.loadtxt(\"german.adcg.trainingd\", comments=\"#\", delimiter=\",\", unpack=False)#np.loadtxt('german.adcg.trainingd')\n",
    "    f = open(fname,'r')\n",
    "    featureMap = {'A11':1,'A12':2,'A13':3,'A14':4,\n",
    "                  'A30':1,'A31':2,'A32':3,'A33':4,'A34':5,\n",
    "                  'A40':1,'A41':2,'A42':3,'A43':4,'A44':5, 'A45':6,'A46':7,'A47':8,'A48':9,'A49':10, 'A410':0,\n",
    "                  'A61':2,'A62':3,'A63':4,'A64':5,'A65':1,\n",
    "                  'A71':1,'A72':2,'A73':3,'A74':4,'A75':5,\n",
    "                  'A91':1,'A92':4,'A93':2,'A94':3,'A95':4,\n",
    "                  'A101':1,'A102':2,'A103':3,\n",
    "                  'A121':4,'A122':3,'A123':2,'A124':1,\n",
    "                  'A141':1,'A142':2,'A143':3,\n",
    "                  'A151':2,'A152':3,'A153':1,\n",
    "                  'A171':1,'A172':2,'A173':3, 'A174':4,\n",
    "                  'A191':1,'A192':2,\n",
    "                  'A201':1,'A202':2}\n",
    "    for line in f:\n",
    "    #     inputLine = np.empty(shape=(1,20))\n",
    "        inputLine = []\n",
    "        numericalData = []\n",
    "        for word in line.split():\n",
    "            if word in featureMap:\n",
    "    #             print featureMap[word]\n",
    "                inputLine.append(featureMap[word])\n",
    "            else:\n",
    "#                 inputLine.append(int(word))\n",
    "                numericalData.append(int(word))\n",
    "#         inputData.append(inputLine)\n",
    "        inputData.append((inputLine + numericalData))\n",
    "    f.close()\n",
    "#     print inputData[0]\n",
    "    inputDatanp = np.array(inputData)\n",
    "\n",
    "    return inputDatanp\n",
    "\n",
    "\n",
    "#print trainedLabels[:3]\n",
    "\n",
    "\n",
    "# Function to write predicted labels for the Test dataset to a file.\n",
    "def writePrdictedLabelFile(YPred):\n",
    "    f = open(\"german.adcg.testing.label\",\"w\")\n",
    "    f.write(\"Id,Prediction\" + \"\\n\")\n",
    "\n",
    "    for i in xrange(len(YPred)):\n",
    "        f.write(str(i+1) + \",\" + str(YPred[i])+ \"\\n\")\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "# Read the input data and labels\n",
    "XTrain = readGermanCreditDataset(\"german.adcg.trainingd\")\n",
    "XTest = readGermanCreditDataset(\"german.adcg.testingd\")\n",
    "Y = np.loadtxt(\"german.adcg.training.label\", delimiter=\",\", skiprows=1, usecols=(1,))\n",
    "\n",
    "#Pre processing the data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encTrain1 = OneHotEncoder()\n",
    "encTrain = encTrain1.fit_transform(XTrain[:,:12]).toarray()\n",
    "\n",
    "encTest1 = OneHotEncoder()\n",
    "encTest = encTest1.fit_transform(XTest[:,:12]).toarray()\n",
    "\n",
    "encNTrain = XTrain[:,13:]\n",
    "encNTest = XTest[:,13:]\n",
    "# print XTest.shape, XTrain.shape\n",
    "# print encNTest.shape, encNTrain.shape\n",
    "\n",
    "# XTrain = np.concatenate((encTrain, encNTrain), axis=1)\n",
    "# XTest = np.concatenate((encTest, encNTest), axis=1)\n",
    "\n",
    "#Normalizing & scaling of data\n",
    "from sklearn import preprocessing\n",
    "# encNTrain = preprocessing.scale(encNTrain)\n",
    "encNTrain = (encNTrain - encNTrain.mean())/encNTrain.std()\n",
    "# encNTest = preprocessing.scale(encNTest)\n",
    "encNTest = (encNTest - encNTest.mean())/encNTest.std()\n",
    "\n",
    "#c = XTrain.reshape((500, 52))\n",
    "XTrain = np.append(encTrain,encNTrain,axis=1)\n",
    "XTest = np.append(encTest,encNTest,axis=1)\n",
    "\n",
    "# print XTrain.shape\n",
    "# print XTest.shape\n",
    "\n",
    "# print 'completed'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split Training Data into Train & Validation, Estimate degrees\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# np.random.seed(9)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(XTrain[:,:12], Y, test_size=0.8)\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(XTrain, Y, test_size=0.8)\n",
    "# #X_train, X_test, y_train, y_test = train_test_split(encNTrain, Y, test_size=0.8)\n",
    "# XTrain = X_train\n",
    "# XTest = X_test\n",
    "# Y = y_train\n",
    "# YTest = y_test\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train_error = np.empty(5)\n",
    "# test_error = np.empty(5)\n",
    "# for degree in xrange(1,6):\n",
    "#     est = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "#     est.fit(X_train, y_train)\n",
    "#     train_error[degree-1] = mean_squared_error(y_train, est.predict(X_train))\n",
    "#     test_error[degree-1] = mean_squared_error(y_test, est.predict(X_test))\n",
    "# print train_error\n",
    "# print test_error\n",
    "\n",
    "# plt.plot(np.arange(5), train_error, color='green', label='train')\n",
    "# plt.plot(np.arange(5), test_error, color='red', label='test')\n",
    "# plt.ylim((0.0, 1e0))\n",
    "# plt.ylabel('log(mean squared error)')\n",
    "# plt.xlabel('degree')\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn import linear_model\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=48)\n",
    "# print XTrain.shape\n",
    "# pca.fit(XTrain)\n",
    "# XTrain = pca.transform(XTrain)\n",
    "# pca.fit(XTest)\n",
    "# XTest = pca.transform(XTest)\n",
    "# print XTrain.shape\n",
    "LR = linear_model.LinearRegression()\n",
    "LR.fit(XTrain, Y)\n",
    "# # LR.fit(encTrain, Y)\n",
    "\n",
    "# Finds the optimal model parameters using a least squares method.\n",
    "\n",
    "# To get the parameter values:\n",
    "LR.get_params()\n",
    "\n",
    "# To predict a new input XTest,\n",
    "YPred = LR.predict(XTest)\n",
    "# YPred = LR.predict(encTest)\n",
    "\n",
    "\n",
    "writePrdictedLabelFile(YPred)\n",
    "\n",
    "# # R^2 statistics to observe the goodness of a line fitting.\n",
    "# LR.score(XTest, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression Cross Validation to select optimal value of penalty alpha to reduce overfitting\n",
    "clfR = linear_model.RidgeCV(alphas=[0.1, 0.3, 0.7, 1.0, 1.3, 1.7, 2, 2.3, 5, 7, 15, 50, 100])\n",
    "clfR.fit(XTrain, Y)\n",
    "print clfR.alpha_\n",
    "\n",
    "# Lasso Regression\n",
    "clflml = linear_model.Lasso(alpha = 0.3)\n",
    "clflml.fit(XTrain, Y)\n",
    "YPred = clflml.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bayesian Ridge\n",
    "clflml = linear_model.BayesianRidge()\n",
    "clflml.fit(XTrain, Y)\n",
    "YPred = clflml.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ARD Regression\n",
    "clflml = linear_model.ARDRegression(compute_score=True)\n",
    "clflml.fit(XTrain, Y)\n",
    "YPred = clflml.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "LogReg = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)\n",
    "LogReg.fit(XTrain, Y)\n",
    "# Finds the optimal model parameters using a least squares method.\n",
    "# To get the parameter values:\n",
    "LogReg.get_params()\n",
    "# To predict a new input XTest,\n",
    "YPred = LogReg.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machines (SVM)\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(XTrain, Y) \n",
    "# To predict a new input XTest\n",
    "YPred = clf.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multi-class classification - Linear SVM\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(XTrain, Y)\n",
    "# To predict a new input XTest\n",
    "YPred = lin_clf.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Non Linear SVM\n",
    "clfnl = svm.NuSVC()\n",
    "clfnl.fit(XTrain, Y)\n",
    "# To predict a new input XTest\n",
    "YPred = clfnl.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM Kernels\n",
    "pca = PCA(n_components=48)\n",
    "pca.fit(XTrain)\n",
    "XTrain = pca.transform(XTrain)\n",
    "pca.fit(XTest)\n",
    "XTest = pca.transform(XTest)\n",
    "# print XTrain.shape\n",
    "linear_svc = svm.SVC(kernel='linear')\n",
    "linear_svc.fit(XTrain, Y)\n",
    "# To predict a new input XTest\n",
    "YPred = linear_svc.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)\n",
    "# rbf_svc = svm.SVC(kernel='rbf')\n",
    "# rbf_svc.fit(XTrain, Y)\n",
    "# # To predict a new input XTest\n",
    "# YPred = rbf_svc.predict(XTest)\n",
    "# writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "from sklearn import linear_model\n",
    "# Setting the regularization parameter: generalized Cross-Validation\n",
    "from sklearn import linear_model\n",
    "clfRidge = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "clfRidge.fit(XTrain, Y)       \n",
    "alpha = clfRidge.alpha_ \n",
    "# print alpha \n",
    "clfRidge = linear_model.Ridge(alpha)\n",
    "clfRidge.fit(XTrain, Y) \n",
    "# print clfRidge.coef_\n",
    "# print clfRidge.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(XTrain, Y)\n",
    "YPred = clf.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision Tree with Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "pca = PCA(n_components=48)\n",
    "pca.fit(XTest)\n",
    "XTest = pca.transform(XTest)\n",
    "pca.fit(XTrain)\n",
    "XTrain = pca.transform(XTrain)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(XTrain, Y)\n",
    "YPred = clf.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pca = PCA(n_components=48)\n",
    "pca.fit(XTest)\n",
    "XTest = pca.transform(XTest)\n",
    "pca.fit(XTrain)\n",
    "XTrain = pca.transform(XTrain)\n",
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf = clf.fit(XTrain, Y)\n",
    "YPred = clf.predict(XTest)\n",
    "writePrdictedLabelFile(YPred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
